{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7d4a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_classif, RFECV, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from warnings import filterwarnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from functools import partial\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a882c2",
   "metadata": {},
   "source": [
    "* read csv\n",
    "* encoding, missing value handling, oversampling\n",
    "* models -> voting classifier for improvements\n",
    "* evaluation\n",
    "* visualization\n",
    "* <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b48cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7c94d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('lucene-solr/dataset/training.csv')\n",
    "test_df = pd.read_csv('lucene-solr/dataset/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27250f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  3657\n",
      "test:  5162\n"
     ]
    }
   ],
   "source": [
    "print('train: ', len(train_df))\n",
    "print('test: ', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576c4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df.dropna(subset=list(df.columns).remove('Bugged'), inplace=True)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x is True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafbdeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Bugged'], axis=1)\n",
    "y_train = train_df['Bugged']\n",
    "\n",
    "X_test = test_df.drop(['Bugged'], axis=1)\n",
    "y_test = test_df['Bugged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0848713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  3657\n",
      "test:  5162\n"
     ]
    }
   ],
   "source": [
    "print('train: ', len(train_df))\n",
    "print('test: ', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1351206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e540c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "        'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n",
    "        'LogisticRegression': LogisticRegression(),\n",
    "        'BernoulliNaiveBayes': BernoulliNB(),\n",
    "        'K-NearestNeighbor': KNeighborsClassifier(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'SupportVectorMachine': SVC(),\n",
    "        'MultilayerPerceptron': MLPClassifier()\n",
    "    }\n",
    "\n",
    "params = {\n",
    "        'LinearDiscriminantAnalysis': {},\n",
    "        'QuadraticDiscriminantAnalysis': {},\n",
    "        'LogisticRegression': {'C': list(np.logspace(-4, 4, 3))},\n",
    "        'BernoulliNaiveBayes': {},\n",
    "        'K-NearestNeighbor': {},\n",
    "        'DecisionTree': {'criterion': ['gini', 'entropy'], },\n",
    "        'RandomForest': {'n_estimators': [10, 100]},\n",
    "        'SupportVectorMachine': {'C': [0.1, 100]},\n",
    "        'MultilayerPerceptron': {'hidden_layer_sizes': [(17, 8, 17)],\n",
    "                                 'activation': ['tanh', 'relu']}\n",
    "    }\n",
    "\n",
    "selection_methods = {\n",
    "        'chi2_20p': SelectPercentile(chi2, percentile=20),\n",
    "        'chi2_50p': SelectPercentile(chi2, percentile=50),\n",
    "        'mutual_info_classif_20p': SelectPercentile(mutual_info_classif, percentile=20),\n",
    "        'mutual_info_classif_50p': SelectPercentile(mutual_info_classif, percentile=50),\n",
    "        'f_classif_20': SelectPercentile(f_classif, percentile=20),\n",
    "        'f_classif_50': SelectPercentile(f_classif, percentile=50),\n",
    "        'recursive_elimination': RFECV(RandomForestClassifier(), min_features_to_select=3, step=1, cv=5, scoring='f1')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63124bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImperativeAbstraction', 'MultifacetedAbstraction',\n",
       "       'UnnecessaryAbstraction', 'UnutilizedAbstraction',\n",
       "       'DeficientEncapsulation', 'UnexploitedEncapsulation',\n",
       "       'BrokenModularization', 'Cyclic_DependentModularization',\n",
       "       'InsufficientModularization', 'Hub_likeModularization',\n",
       "       'BrokenHierarchy', 'CyclicHierarchy', 'DeepHierarchy',\n",
       "       'MissingHierarchy', 'MultipathHierarchy', 'RebelliousHierarchy',\n",
       "       'WideHierarchy', 'GodClass', 'ClassDataShouldBePrivate', 'ComplexClass',\n",
       "       'LazyClass', 'RefusedBequest', 'SpaghettiCode', 'SpeculativeGenerality',\n",
       "       'DataClass', 'BrainClass', 'LargeClass', 'SwissArmyKnife',\n",
       "       'AntiSingleton', 'FeatureEnvy', 'LongMethod_Organic',\n",
       "       'LongParameterList_Organic', 'MessageChain', 'DispersedCoupling',\n",
       "       'IntensiveCoupling', 'ShotgunSurgery', 'BrainMethod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def select(X, y):\n",
    "#     selected_data = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "#     selected_features = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "#     features = X.columns\n",
    "#     for method_name, method in selection_methods.items():\n",
    "#         selected_data[method_name] = method.fit_transform(X, y).tolist()\n",
    "#         features_mask = method.get_support()\n",
    "#         selected_features[method_name] = np.array(features)[features_mask].tolist()\n",
    "#         print(np.array(features)[features_mask].tolist())\n",
    "# #     selected_data['all'] = X\n",
    "# #     selected_features['all'] = list(features)\n",
    "#     return selected_features, selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e406f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = {}\n",
    "selected_features = {}\n",
    "features = X_train.columns\n",
    "for method_name, method in selection_methods.items():\n",
    "    selected_data[method_name] = method.fit_transform(X_train, y_train)\n",
    "    features_mask = method.get_support()\n",
    "    selected_features[method_name] = np.array(features)[features_mask].tolist()\n",
    "selected_data['all'] = X_train\n",
    "selected_features['all'] = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4415b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "# selected_features = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "\n",
    "# selected_features_train, selected_data_train = select(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bfa56995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data\n",
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "edd2ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_datasets = {method: SMOTE().fit_resample(X_train, y_train) for method, X_train in selected_data.items()}\n",
    "\n",
    "# selected_features, selected_dataset = select(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a167cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_testing(test_df, selected_features):\n",
    "    features = test_df.columns\n",
    "    test_y = test_df['Bugged']\n",
    "    selected_testing_datasets = {\n",
    "    method: (test_df[test_df.columns.intersection(features)].values, test_y)\n",
    "    for method, features in selected_features.items()\n",
    "    }\n",
    "    return selected_testing_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d89616ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_testing_datasets = get_selected_testing(test_df, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "76c0df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_testing_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ad4800b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7b2190c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, cv=5, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "    for key in models.keys():\n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=cv, n_jobs=n_jobs, verbose=verbose,\n",
    "                          scoring=scoring, refit=refit, return_train_score=True)\n",
    "        gs.fit(X, y)\n",
    "        grid_searches[key] = gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fc13758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_summary(sort_by='mean_score'):\n",
    "\n",
    "    def extract_rows(key: str):\n",
    "        def get_cv_results(cv, params):\n",
    "            key = \"split{}_test_score\".format(cv)\n",
    "            return grid_search.cv_results_[key]\n",
    "\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': np.min(scores),\n",
    "                'max_score': np.max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores)\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "    \n",
    "        grid_search = grid_searches[key]\n",
    "        params = grid_search.cv_results_['params']\n",
    "        get_cv_results_with_params = partial(get_cv_results, params=params)\n",
    "        scores = np.hstack(list(map(get_cv_results_with_params, range(grid_search.cv))))\n",
    "        summary = list(map(lambda values:\n",
    "                           row(key, values[1], values[0]),\n",
    "                           list(zip(params, scores))))\n",
    "        return summary\n",
    "    \n",
    "    rows = list(itertools.chain.from_iterable(map(extract_rows, grid_searches.keys())))\n",
    "    df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "    columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "    columns = columns + [c for c in df.columns if c not in columns]\n",
    "    return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7e862371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(X, y):\n",
    "    fit(X, y)\n",
    "    return score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1bcf41ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ImperativeAbstraction  MultifacetedAbstraction  UnnecessaryAbstraction  \\\n",
      "0                         0                        0                       0   \n",
      "1                         0                        0                       0   \n",
      "2                         0                        0                       0   \n",
      "3                         0                        0                       0   \n",
      "4                         1                        0                       0   \n",
      "...                     ...                      ...                     ...   \n",
      "3652                      0                        0                       0   \n",
      "3653                      0                        0                       0   \n",
      "3654                      0                        0                       0   \n",
      "3655                      0                        0                       0   \n",
      "3656                      0                        0                       0   \n",
      "\n",
      "      UnutilizedAbstraction  DeficientEncapsulation  UnexploitedEncapsulation  \\\n",
      "0                         0                       0                         0   \n",
      "1                         1                       1                         0   \n",
      "2                         1                       0                         0   \n",
      "3                         1                       0                         0   \n",
      "4                         0                       1                         0   \n",
      "...                     ...                     ...                       ...   \n",
      "3652                      0                       0                         0   \n",
      "3653                      0                       0                         0   \n",
      "3654                      0                       0                         0   \n",
      "3655                      0                       0                         0   \n",
      "3656                      0                       0                         0   \n",
      "\n",
      "      BrokenModularization  Cyclic_DependentModularization  \\\n",
      "0                        0                               0   \n",
      "1                        0                               0   \n",
      "2                        0                               0   \n",
      "3                        0                               0   \n",
      "4                        0                               0   \n",
      "...                    ...                             ...   \n",
      "3652                     0                               0   \n",
      "3653                     0                               0   \n",
      "3654                     0                               0   \n",
      "3655                     0                               0   \n",
      "3656                     0                               0   \n",
      "\n",
      "      InsufficientModularization  Hub_likeModularization  ...  SwissArmyKnife  \\\n",
      "0                              1                       0  ...               0   \n",
      "1                              0                       0  ...               0   \n",
      "2                              0                       0  ...               0   \n",
      "3                              0                       0  ...               0   \n",
      "4                              0                       0  ...               0   \n",
      "...                          ...                     ...  ...             ...   \n",
      "3652                           0                       0  ...               0   \n",
      "3653                           0                       0  ...               0   \n",
      "3654                           0                       0  ...               0   \n",
      "3655                           0                       0  ...               0   \n",
      "3656                           0                       0  ...               0   \n",
      "\n",
      "      AntiSingleton  FeatureEnvy  LongMethod_Organic  \\\n",
      "0                 0            0                   1   \n",
      "1                 0            0                   0   \n",
      "2                 0            0                   1   \n",
      "3                 0            0                   0   \n",
      "4                 0            0                   1   \n",
      "...             ...          ...                 ...   \n",
      "3652              0            1                   1   \n",
      "3653              0            1                   0   \n",
      "3654              0            1                   0   \n",
      "3655              0            1                   0   \n",
      "3656              0            1                   0   \n",
      "\n",
      "      LongParameterList_Organic  MessageChain  DispersedCoupling  \\\n",
      "0                             0             0                  0   \n",
      "1                             0             0                  0   \n",
      "2                             0             0                  0   \n",
      "3                             0             0                  0   \n",
      "4                             0             0                  0   \n",
      "...                         ...           ...                ...   \n",
      "3652                          0             0                  0   \n",
      "3653                          0             0                  0   \n",
      "3654                          0             0                  0   \n",
      "3655                          0             0                  0   \n",
      "3656                          0             0                  0   \n",
      "\n",
      "      IntensiveCoupling  ShotgunSurgery  BrainMethod  \n",
      "0                     0               0            0  \n",
      "1                     0               0            0  \n",
      "2                     0               0            1  \n",
      "3                     0               0            0  \n",
      "4                     0               0            0  \n",
      "...                 ...             ...          ...  \n",
      "3652                  1               0            0  \n",
      "3653                  0               0            0  \n",
      "3654                  0               0            0  \n",
      "3655                  0               0            0  \n",
      "3656                  0               0            0  \n",
      "\n",
      "[3657 rows x 37 columns] 0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "3652    0\n",
      "3653    0\n",
      "3654    0\n",
      "3655    0\n",
      "3656    0\n",
      "Name: Bugged, Length: 3657, dtype: int64\n",
      "\n",
      "{'chi2_20p': array([[0, 0, 1, ..., 0, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'chi2_50p': array([[0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 1],\n",
      "       [0, 0, 0, ..., 0, 0, 1],\n",
      "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64), 'mutual_info_classif_20p': array([[0, 0, 1, ..., 0, 0, 1],\n",
      "       [0, 1, 0, ..., 1, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'mutual_info_classif_50p': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 1, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 1],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'f_classif_20': array([[0, 0, 1, ..., 0, 1, 1],\n",
      "       [1, 1, 0, ..., 1, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'f_classif_50': array([[0, 0, 0, ..., 1, 0, 0],\n",
      "       [0, 1, 1, ..., 0, 0, 0],\n",
      "       [0, 1, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 0, 1, 0],\n",
      "       [0, 0, 0, ..., 0, 1, 0]], dtype=int64), 'recursive_elimination': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 1, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), 'all':       ImperativeAbstraction  MultifacetedAbstraction  UnnecessaryAbstraction  \\\n",
      "0                         0                        0                       0   \n",
      "1                         0                        0                       0   \n",
      "2                         0                        0                       0   \n",
      "3                         0                        0                       0   \n",
      "4                         1                        0                       0   \n",
      "...                     ...                      ...                     ...   \n",
      "3652                      0                        0                       0   \n",
      "3653                      0                        0                       0   \n",
      "3654                      0                        0                       0   \n",
      "3655                      0                        0                       0   \n",
      "3656                      0                        0                       0   \n",
      "\n",
      "      UnutilizedAbstraction  DeficientEncapsulation  UnexploitedEncapsulation  \\\n",
      "0                         0                       0                         0   \n",
      "1                         1                       1                         0   \n",
      "2                         1                       0                         0   \n",
      "3                         1                       0                         0   \n",
      "4                         0                       1                         0   \n",
      "...                     ...                     ...                       ...   \n",
      "3652                      0                       0                         0   \n",
      "3653                      0                       0                         0   \n",
      "3654                      0                       0                         0   \n",
      "3655                      0                       0                         0   \n",
      "3656                      0                       0                         0   \n",
      "\n",
      "      BrokenModularization  Cyclic_DependentModularization  \\\n",
      "0                        0                               0   \n",
      "1                        0                               0   \n",
      "2                        0                               0   \n",
      "3                        0                               0   \n",
      "4                        0                               0   \n",
      "...                    ...                             ...   \n",
      "3652                     0                               0   \n",
      "3653                     0                               0   \n",
      "3654                     0                               0   \n",
      "3655                     0                               0   \n",
      "3656                     0                               0   \n",
      "\n",
      "      InsufficientModularization  Hub_likeModularization  ...  SwissArmyKnife  \\\n",
      "0                              1                       0  ...               0   \n",
      "1                              0                       0  ...               0   \n",
      "2                              0                       0  ...               0   \n",
      "3                              0                       0  ...               0   \n",
      "4                              0                       0  ...               0   \n",
      "...                          ...                     ...  ...             ...   \n",
      "3652                           0                       0  ...               0   \n",
      "3653                           0                       0  ...               0   \n",
      "3654                           0                       0  ...               0   \n",
      "3655                           0                       0  ...               0   \n",
      "3656                           0                       0  ...               0   \n",
      "\n",
      "      AntiSingleton  FeatureEnvy  LongMethod_Organic  \\\n",
      "0                 0            0                   1   \n",
      "1                 0            0                   0   \n",
      "2                 0            0                   1   \n",
      "3                 0            0                   0   \n",
      "4                 0            0                   1   \n",
      "...             ...          ...                 ...   \n",
      "3652              0            1                   1   \n",
      "3653              0            1                   0   \n",
      "3654              0            1                   0   \n",
      "3655              0            1                   0   \n",
      "3656              0            1                   0   \n",
      "\n",
      "      LongParameterList_Organic  MessageChain  DispersedCoupling  \\\n",
      "0                             0             0                  0   \n",
      "1                             0             0                  0   \n",
      "2                             0             0                  0   \n",
      "3                             0             0                  0   \n",
      "4                             0             0                  0   \n",
      "...                         ...           ...                ...   \n",
      "3652                          0             0                  0   \n",
      "3653                          0             0                  0   \n",
      "3654                          0             0                  0   \n",
      "3655                          0             0                  0   \n",
      "3656                          0             0                  0   \n",
      "\n",
      "      IntensiveCoupling  ShotgunSurgery  BrainMethod  \n",
      "0                     0               0            0  \n",
      "1                     0               0            0  \n",
      "2                     0               0            1  \n",
      "3                     0               0            0  \n",
      "4                     0               0            0  \n",
      "...                 ...             ...          ...  \n",
      "3652                  1               0            0  \n",
      "3653                  0               0            0  \n",
      "3654                  0               0            0  \n",
      "3655                  0               0            0  \n",
      "3656                  0               0            0  \n",
      "\n",
      "[3657 rows x 37 columns]}\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)\n",
    "print()\n",
    "print(selected_data)\n",
    "# for method, data in selected_data.items():\n",
    "#     print(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "526a4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 1 1] [1 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0] [0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 1 1 1 0 0 1] [0 1 0 0 0 1 0 0]\n",
      "[0 0 0 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0] [1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 1 1] [1 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0] [0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 1 0 0 1 1 0 0 0 0] [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for method, data in selected_data.items():\n",
    "    try:\n",
    "        print(data[0], data[1])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "880321c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "summaries = {method: get_summary(data[0], data[1])\n",
    "                     for method, data in oversampled_datasets.items()}\n",
    "\n",
    "# top_summaries = {method: summary[:n] for method, summary in summaries.items()}\n",
    "\n",
    "# configurations = {method: list(map(lambda x: x[1].to_dict(),\n",
    "#                                            top_summary.drop(EstimatorSelectionHelper.get_scores_info(),\n",
    "#                                                             axis=1)\n",
    "#                                            .where(pd.notnull(top_summary), None).iterrows()))\n",
    "#                           for method, top_summary in top_summaries.items()}\n",
    "\n",
    "# method_names = configurations.keys()\n",
    "#         scores_dicts = list(map(lambda method_name:\n",
    "#                                 list(map(lambda configuration:\n",
    "#                                          calculate_score(method_name,\n",
    "#                                                          oversampled_training[method_name],\n",
    "#                                                          selected_testing[method_name],\n",
    "#                                                          configuration),\n",
    "#                                          configurations[method_name])), method_names))\n",
    "#         scores_df = [pd.DataFrame(score) for score in scores_dicts]\n",
    "#         scores = pd.concat(scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "265c9d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chi2_20p':                         estimator min_score mean_score max_score std_score  \\\n",
       " 9                    RandomForest   0.73965    0.73965   0.73965       0.0   \n",
       " 13           MultilayerPerceptron   0.73965    0.73965   0.73965       0.0   \n",
       " 7                    DecisionTree  0.738057   0.738057  0.738057       0.0   \n",
       " 8                    DecisionTree  0.738057   0.738057  0.738057       0.0   \n",
       " 10                   RandomForest  0.738057   0.738057  0.738057       0.0   \n",
       " 12           SupportVectorMachine  0.738057   0.738057  0.738057       0.0   \n",
       " 14           MultilayerPerceptron  0.738057   0.738057  0.738057       0.0   \n",
       " 11           SupportVectorMachine  0.730096   0.730096  0.730096       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.669586   0.669586  0.669586       0.0   \n",
       " 2              LogisticRegression  0.622611   0.622611  0.622611       0.0   \n",
       " 5             BernoulliNaiveBayes  0.620223   0.620223  0.620223       0.0   \n",
       " 3              LogisticRegression  0.615446   0.615446  0.615446       0.0   \n",
       " 4              LogisticRegression  0.615446   0.615446  0.615446       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.607484   0.607484  0.607484       0.0   \n",
       " 6               K-NearestNeighbor  0.540605   0.540605  0.540605       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'chi2_50p':                         estimator min_score mean_score max_score std_score  \\\n",
       " 13           MultilayerPerceptron  0.769904   0.769904  0.769904       0.0   \n",
       " 14           MultilayerPerceptron  0.763535   0.763535  0.763535       0.0   \n",
       " 9                    RandomForest  0.759554   0.759554  0.759554       0.0   \n",
       " 10                   RandomForest  0.758758   0.758758  0.758758       0.0   \n",
       " 12           SupportVectorMachine  0.757962   0.757962  0.757962       0.0   \n",
       " 7                    DecisionTree  0.756369   0.756369  0.756369       0.0   \n",
       " 8                    DecisionTree  0.756369   0.756369  0.756369       0.0   \n",
       " 11           SupportVectorMachine  0.746019   0.746019  0.746019       0.0   \n",
       " 6               K-NearestNeighbor  0.742834   0.742834  0.742834       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.680732   0.680732  0.680732       0.0   \n",
       " 3              LogisticRegression  0.679936   0.679936  0.679936       0.0   \n",
       " 4              LogisticRegression  0.679936   0.679936  0.679936       0.0   \n",
       " 2              LogisticRegression  0.657643   0.657643  0.657643       0.0   \n",
       " 5             BernoulliNaiveBayes  0.654459   0.654459  0.654459       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis       0.5        0.5       0.5       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'mutual_info_classif_20p':                         estimator min_score mean_score max_score std_score  \\\n",
       " 7                    DecisionTree  0.741242   0.741242  0.741242       0.0   \n",
       " 8                    DecisionTree  0.741242   0.741242  0.741242       0.0   \n",
       " 9                    RandomForest  0.741242   0.741242  0.741242       0.0   \n",
       " 10                   RandomForest  0.741242   0.741242  0.741242       0.0   \n",
       " 12           SupportVectorMachine  0.741242   0.741242  0.741242       0.0   \n",
       " 14           MultilayerPerceptron  0.738057   0.738057  0.738057       0.0   \n",
       " 11           SupportVectorMachine  0.737261   0.737261  0.737261       0.0   \n",
       " 13           MultilayerPerceptron   0.73328    0.73328   0.73328       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.666401   0.666401  0.666401       0.0   \n",
       " 3              LogisticRegression  0.666401   0.666401  0.666401       0.0   \n",
       " 4              LogisticRegression  0.666401   0.666401  0.666401       0.0   \n",
       " 2              LogisticRegression  0.664013   0.664013  0.664013       0.0   \n",
       " 5             BernoulliNaiveBayes  0.661624   0.661624  0.661624       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.628981   0.628981  0.628981       0.0   \n",
       " 6               K-NearestNeighbor  0.505573   0.505573  0.505573       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'mutual_info_classif_50p':                         estimator min_score mean_score max_score std_score  \\\n",
       " 10                   RandomForest  0.750796   0.750796  0.750796       0.0   \n",
       " 12           SupportVectorMachine      0.75       0.75      0.75       0.0   \n",
       " 7                    DecisionTree  0.748408   0.748408  0.748408       0.0   \n",
       " 14           MultilayerPerceptron  0.748408   0.748408  0.748408       0.0   \n",
       " 8                    DecisionTree  0.747611   0.747611  0.747611       0.0   \n",
       " 9                    RandomForest  0.747611   0.747611  0.747611       0.0   \n",
       " 13           MultilayerPerceptron  0.746019   0.746019  0.746019       0.0   \n",
       " 11           SupportVectorMachine  0.740446   0.740446  0.740446       0.0   \n",
       " 6               K-NearestNeighbor  0.710987   0.710987  0.710987       0.0   \n",
       " 5             BernoulliNaiveBayes  0.648885   0.648885  0.648885       0.0   \n",
       " 4              LogisticRegression  0.644108   0.644108  0.644108       0.0   \n",
       " 3              LogisticRegression  0.643312   0.643312  0.643312       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.636943   0.636943  0.636943       0.0   \n",
       " 2              LogisticRegression  0.621815   0.621815  0.621815       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.501592   0.501592  0.501592       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'f_classif_20':                         estimator min_score mean_score max_score std_score  \\\n",
       " 10                   RandomForest  0.735669   0.735669  0.735669       0.0   \n",
       " 7                    DecisionTree  0.734076   0.734076  0.734076       0.0   \n",
       " 8                    DecisionTree  0.734076   0.734076  0.734076       0.0   \n",
       " 12           SupportVectorMachine  0.732484   0.732484  0.732484       0.0   \n",
       " 14           MultilayerPerceptron  0.731688   0.731688  0.731688       0.0   \n",
       " 9                    RandomForest  0.730096   0.730096  0.730096       0.0   \n",
       " 13           MultilayerPerceptron  0.726911   0.726911  0.726911       0.0   \n",
       " 11           SupportVectorMachine  0.724522   0.724522  0.724522       0.0   \n",
       " 2              LogisticRegression     0.625      0.625     0.625       0.0   \n",
       " 5             BernoulliNaiveBayes  0.622611   0.622611  0.622611       0.0   \n",
       " 3              LogisticRegression  0.621815   0.621815  0.621815       0.0   \n",
       " 4              LogisticRegression  0.621815   0.621815  0.621815       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.609873   0.609873  0.609873       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.609076   0.609076  0.609076       0.0   \n",
       " 6               K-NearestNeighbor  0.531051   0.531051  0.531051       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'f_classif_50':                         estimator min_score mean_score max_score std_score  \\\n",
       " 12           SupportVectorMachine  0.767516   0.767516  0.767516       0.0   \n",
       " 10                   RandomForest   0.76672    0.76672   0.76672       0.0   \n",
       " 9                    RandomForest  0.765924   0.765924  0.765924       0.0   \n",
       " 8                    DecisionTree  0.765127   0.765127  0.765127       0.0   \n",
       " 7                    DecisionTree  0.763535   0.763535  0.763535       0.0   \n",
       " 13           MultilayerPerceptron  0.756369   0.756369  0.756369       0.0   \n",
       " 11           SupportVectorMachine  0.753981   0.753981  0.753981       0.0   \n",
       " 14           MultilayerPerceptron  0.752389   0.752389  0.752389       0.0   \n",
       " 6               K-NearestNeighbor  0.719745   0.719745  0.719745       0.0   \n",
       " 2              LogisticRegression  0.688694   0.688694  0.688694       0.0   \n",
       " 3              LogisticRegression  0.677548   0.677548  0.677548       0.0   \n",
       " 4              LogisticRegression  0.677548   0.677548  0.677548       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.676752   0.676752  0.676752       0.0   \n",
       " 5             BernoulliNaiveBayes  0.676752   0.676752  0.676752       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis       0.5        0.5       0.5       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'recursive_elimination':                         estimator min_score mean_score max_score std_score  \\\n",
       " 7                    DecisionTree  0.781847   0.781847  0.781847       0.0   \n",
       " 12           SupportVectorMachine  0.781051   0.781051  0.781051       0.0   \n",
       " 8                    DecisionTree  0.780255   0.780255  0.780255       0.0   \n",
       " 10                   RandomForest  0.780255   0.780255  0.780255       0.0   \n",
       " 14           MultilayerPerceptron  0.775478   0.775478  0.775478       0.0   \n",
       " 13           MultilayerPerceptron  0.770701   0.770701  0.770701       0.0   \n",
       " 9                    RandomForest  0.769108   0.769108  0.769108       0.0   \n",
       " 11           SupportVectorMachine  0.761943   0.761943  0.761943       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.694268   0.694268  0.694268       0.0   \n",
       " 0      LinearDiscriminantAnalysis   0.68949    0.68949   0.68949       0.0   \n",
       " 2              LogisticRegression  0.673567   0.673567  0.673567       0.0   \n",
       " 4              LogisticRegression  0.667197   0.667197  0.667197       0.0   \n",
       " 3              LogisticRegression  0.665605   0.665605  0.665605       0.0   \n",
       " 5             BernoulliNaiveBayes  0.663217   0.663217  0.663217       0.0   \n",
       " 6               K-NearestNeighbor  0.607484   0.607484  0.607484       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  ,\n",
       " 'all':                         estimator min_score mean_score max_score std_score  \\\n",
       " 9                    RandomForest  0.784236   0.784236  0.784236       0.0   \n",
       " 12           SupportVectorMachine  0.781051   0.781051  0.781051       0.0   \n",
       " 13           MultilayerPerceptron  0.776274   0.776274  0.776274       0.0   \n",
       " 10                   RandomForest  0.775478   0.775478  0.775478       0.0   \n",
       " 14           MultilayerPerceptron  0.765924   0.765924  0.765924       0.0   \n",
       " 8                    DecisionTree  0.765127   0.765127  0.765127       0.0   \n",
       " 7                    DecisionTree  0.762739   0.762739  0.762739       0.0   \n",
       " 6               K-NearestNeighbor  0.761146   0.761146  0.761146       0.0   \n",
       " 11           SupportVectorMachine  0.757166   0.757166  0.757166       0.0   \n",
       " 0      LinearDiscriminantAnalysis  0.715764   0.715764  0.715764       0.0   \n",
       " 3              LogisticRegression  0.710191   0.710191  0.710191       0.0   \n",
       " 4              LogisticRegression  0.707803   0.707803  0.707803       0.0   \n",
       " 2              LogisticRegression  0.691879   0.691879  0.691879       0.0   \n",
       " 5             BernoulliNaiveBayes  0.686306   0.686306  0.686306       0.0   \n",
       " 1   QuadraticDiscriminantAnalysis  0.585987   0.585987  0.585987       0.0   \n",
       " \n",
       "           C criterion n_estimators activation hidden_layer_sizes  \n",
       " 9       NaN       NaN           10        NaN                NaN  \n",
       " 12      100       NaN          NaN        NaN                NaN  \n",
       " 13      NaN       NaN          NaN       tanh        (17, 8, 17)  \n",
       " 10      NaN       NaN          100        NaN                NaN  \n",
       " 14      NaN       NaN          NaN       relu        (17, 8, 17)  \n",
       " 8       NaN   entropy          NaN        NaN                NaN  \n",
       " 7       NaN      gini          NaN        NaN                NaN  \n",
       " 6       NaN       NaN          NaN        NaN                NaN  \n",
       " 11      0.1       NaN          NaN        NaN                NaN  \n",
       " 0       NaN       NaN          NaN        NaN                NaN  \n",
       " 3       1.0       NaN          NaN        NaN                NaN  \n",
       " 4   10000.0       NaN          NaN        NaN                NaN  \n",
       " 2    0.0001       NaN          NaN        NaN                NaN  \n",
       " 5       NaN       NaN          NaN        NaN                NaN  \n",
       " 1       NaN       NaN          NaN        NaN                NaN  }"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca8cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
