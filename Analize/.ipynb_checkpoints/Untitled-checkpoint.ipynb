{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7d4a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import preprocessing\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_classif, RFECV, mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, brier_score_loss\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from warnings import filterwarnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from functools import partial\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a882c2",
   "metadata": {},
   "source": [
    "* read csv\n",
    "* encoding, missing value handling, oversampling\n",
    "* models -> voting classifier for improvements\n",
    "* evaluation\n",
    "* visualization\n",
    "* <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b48cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7c94d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('lucene-solr/dataset/training.csv')\n",
    "test_df = pd.read_csv('lucene-solr/dataset/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27250f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  3657\n",
      "test:  5162\n"
     ]
    }
   ],
   "source": [
    "print('train: ', len(train_df))\n",
    "print('test: ', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576c4328",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    df.dropna(subset=list(df.columns).remove('Bugged'), inplace=True)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: 1 if x is True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafbdeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Bugged'], axis=1)\n",
    "y_train = train_df['Bugged']\n",
    "\n",
    "X_test = test_df.drop(['Bugged'], axis=1)\n",
    "y_test = test_df['Bugged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0848713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  3657\n",
      "test:  5162\n"
     ]
    }
   ],
   "source": [
    "print('train: ', len(train_df))\n",
    "print('test: ', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1351206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e540c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "        'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "        'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n",
    "        'LogisticRegression': LogisticRegression(),\n",
    "        'BernoulliNaiveBayes': BernoulliNB(),\n",
    "        'K-NearestNeighbor': KNeighborsClassifier(),\n",
    "        'DecisionTree': DecisionTreeClassifier(),\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'SupportVectorMachine': SVC(),\n",
    "        'MultilayerPerceptron': MLPClassifier()\n",
    "    }\n",
    "\n",
    "params = {\n",
    "        'LinearDiscriminantAnalysis': {},\n",
    "        'QuadraticDiscriminantAnalysis': {},\n",
    "        'LogisticRegression': {'C': list(np.logspace(-4, 4, 3))},\n",
    "        'BernoulliNaiveBayes': {},\n",
    "        'K-NearestNeighbor': {},\n",
    "        'DecisionTree': {'criterion': ['gini', 'entropy'], },\n",
    "        'RandomForest': {'n_estimators': [10, 100]},\n",
    "        'SupportVectorMachine': {'C': [0.1, 100]},\n",
    "        'MultilayerPerceptron': {'hidden_layer_sizes': [(17, 8, 17)],\n",
    "                                 'activation': ['tanh', 'relu']}\n",
    "    }\n",
    "\n",
    "selection_methods = {\n",
    "        'chi2_20p': SelectPercentile(chi2, percentile=20),\n",
    "        'chi2_50p': SelectPercentile(chi2, percentile=50),\n",
    "        'mutual_info_classif_20p': SelectPercentile(mutual_info_classif, percentile=20),\n",
    "        'mutual_info_classif_50p': SelectPercentile(mutual_info_classif, percentile=50),\n",
    "        'f_classif_20': SelectPercentile(f_classif, percentile=20),\n",
    "        'f_classif_50': SelectPercentile(f_classif, percentile=50),\n",
    "        'recursive_elimination': RFECV(RandomForestClassifier(), min_features_to_select=3, step=1, cv=5, scoring='f1')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d63124bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImperativeAbstraction', 'MultifacetedAbstraction',\n",
       "       'UnnecessaryAbstraction', 'UnutilizedAbstraction',\n",
       "       'DeficientEncapsulation', 'UnexploitedEncapsulation',\n",
       "       'BrokenModularization', 'Cyclic_DependentModularization',\n",
       "       'InsufficientModularization', 'Hub_likeModularization',\n",
       "       'BrokenHierarchy', 'CyclicHierarchy', 'DeepHierarchy',\n",
       "       'MissingHierarchy', 'MultipathHierarchy', 'RebelliousHierarchy',\n",
       "       'WideHierarchy', 'GodClass', 'ClassDataShouldBePrivate', 'ComplexClass',\n",
       "       'LazyClass', 'RefusedBequest', 'SpaghettiCode', 'SpeculativeGenerality',\n",
       "       'DataClass', 'BrainClass', 'LargeClass', 'SwissArmyKnife',\n",
       "       'AntiSingleton', 'FeatureEnvy', 'LongMethod_Organic',\n",
       "       'LongParameterList_Organic', 'MessageChain', 'DispersedCoupling',\n",
       "       'IntensiveCoupling', 'ShotgunSurgery', 'BrainMethod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def select(X, y):\n",
    "#     selected_data = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "#     selected_features = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "#     features = X.columns\n",
    "#     for method_name, method in selection_methods.items():\n",
    "#         selected_data[method_name] = method.fit_transform(X, y).tolist()\n",
    "#         features_mask = method.get_support()\n",
    "#         selected_features[method_name] = np.array(features)[features_mask].tolist()\n",
    "#         print(np.array(features)[features_mask].tolist())\n",
    "# #     selected_data['all'] = X\n",
    "# #     selected_features['all'] = list(features)\n",
    "#     return selected_features, selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65dc5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = {}\n",
    "selected_features = {}\n",
    "features = X_train.columns\n",
    "for method_name, method in selection_methods.items():\n",
    "    selected_data[method_name] = method.fit_transform(X_train, y_train)\n",
    "    features_mask = method.get_support()\n",
    "    selected_features[method_name] = np.array(features)[features_mask].tolist()\n",
    "# self.selected_data['all'] = X\n",
    "# self.selected_features['all'] = list(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4415b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "# selected_features = pd.DataFrame(columns=list(selection_methods.keys()))\n",
    "\n",
    "# selected_features_train, selected_data_train = select(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87f8db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data\n",
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edd2ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampled_datasets = {method: SMOTE().fit_resample(X_train, y_train) for method, X_train in selected_data.items()}\n",
    "\n",
    "# selected_features, selected_dataset = select(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a167cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_testing(test_df, selected_features):\n",
    "    features = test_df.columns\n",
    "    test_y = test_df['Bugged']\n",
    "    selected_testing_datasets = {\n",
    "    method: (test_df[test_df.columns.intersection(features)].values, test_y)\n",
    "    for method, features in selected_features.items()\n",
    "    }\n",
    "    return selected_testing_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d89616ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_testing_datasets = get_selected_testing(test_df, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84e5ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_testing_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad4800b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b2190c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, cv=5, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "    for key in models.keys():\n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=cv, n_jobs=n_jobs, verbose=verbose,\n",
    "                          scoring=scoring, refit=refit, return_train_score=True)\n",
    "        gs.fit(X, y)\n",
    "        grid_searches[key] = gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc13758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_summary(sort_by='mean_score'):\n",
    "\n",
    "    def extract_rows(key: str):\n",
    "        def get_cv_results(cv, params):\n",
    "            key = \"split{}_test_score\".format(cv)\n",
    "            return grid_search.cv_results_[key]\n",
    "\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': np.min(scores),\n",
    "                'max_score': np.max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores)\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "    \n",
    "        grid_search = grid_searches[key]\n",
    "        params = grid_search.cv_results_['params']\n",
    "        get_cv_results_with_params = partial(get_cv_results, params=params)\n",
    "        scores = np.hstack(list(map(get_cv_results_with_params, range(grid_search.cv))))\n",
    "        summary = list(map(lambda values:\n",
    "                           row(key, values[1], values[0]),\n",
    "                           list(zip(params, scores))))\n",
    "        return summary\n",
    "    \n",
    "    rows = list(itertools.chain.from_iterable(map(extract_rows, grid_searches.keys())))\n",
    "    df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "    columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "    columns = columns + [c for c in df.columns if c not in columns]\n",
    "    return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7e862371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(X, y):\n",
    "    fit(X, y)\n",
    "    return score_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cd0a0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 0 0 1 1] [1 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0] [0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 1 1 0 1 0 0 0] [1 0 0 1 0 0 0 0]\n",
      "[0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0] [0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 1 1] [1 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0] [0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 0 0] [1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(X_train, y_train)\n",
    "for method, data in selected_data.items():\n",
    "    print(data[0], data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f4a608eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data['y'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "526a4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_summary(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "880321c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 1. 0. 0. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 1. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 1. 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summaries \u001b[38;5;241m=\u001b[39m {method: get_summary(data[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      2\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m method, data \u001b[38;5;129;01min\u001b[39;00m selected_data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# top_summaries = {method: summary[:n] for method, summary in summaries.items()}\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# configurations = {method: list(map(lambda x: x[1].to_dict(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#         scores_df = [pd.DataFrame(score) for score in scores_dicts]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#         scores = pd.concat(scores_df)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[118], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summaries \u001b[38;5;241m=\u001b[39m {method: \u001b[43mget_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m method, data \u001b[38;5;129;01min\u001b[39;00m selected_data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# top_summaries = {method: summary[:n] for method, summary in summaries.items()}\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# configurations = {method: list(map(lambda x: x[1].to_dict(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#         scores_df = [pd.DataFrame(score) for score in scores_dicts]\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#         scores = pd.concat(scores_df)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m, in \u001b[0;36mget_summary\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_summary\u001b[39m(X, y):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score_summary()\n",
      "Cell \u001b[1;32mIn[70], line 7\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[0;32m      4\u001b[0m param \u001b[38;5;241m=\u001b[39m params[key]\n\u001b[0;32m      5\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param, cv\u001b[38;5;241m=\u001b[39mcv, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m      6\u001b[0m                   scoring\u001b[38;5;241m=\u001b[39mscoring, refit\u001b[38;5;241m=\u001b[39mrefit, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m grid_searches[key] \u001b[38;5;241m=\u001b[39m gs\n",
      "File \u001b[1;32mD:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    850\u001b[0m     )\n\u001b[1;32m--> 852\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mD:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 1. 0. 0. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 1. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\discriminant_analysis.py\", line 575, in fit\n    X, y = self._validate_data(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\base.py\", line 554, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1104, in check_X_y\n    X = check_array(\n  File \"D:\\IUST\\4011\\Software Architecture\\imple\\Exploring-Design-smells-for-smell-based-defect-prediction\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 900, in check_array\n    raise ValueError(\nValueError: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 1. 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n"
     ]
    }
   ],
   "source": [
    "summaries = {method: get_summary(data[0], data[1])\n",
    "                     for method, data in selected_data.items()}\n",
    "\n",
    "# top_summaries = {method: summary[:n] for method, summary in summaries.items()}\n",
    "\n",
    "# configurations = {method: list(map(lambda x: x[1].to_dict(),\n",
    "#                                            top_summary.drop(EstimatorSelectionHelper.get_scores_info(),\n",
    "#                                                             axis=1)\n",
    "#                                            .where(pd.notnull(top_summary), None).iterrows()))\n",
    "#                           for method, top_summary in top_summaries.items()}\n",
    "\n",
    "# method_names = configurations.keys()\n",
    "#         scores_dicts = list(map(lambda method_name:\n",
    "#                                 list(map(lambda configuration:\n",
    "#                                          calculate_score(method_name,\n",
    "#                                                          oversampled_training[method_name],\n",
    "#                                                          selected_testing[method_name],\n",
    "#                                                          configuration),\n",
    "#                                          configurations[method_name])), method_names))\n",
    "#         scores_df = [pd.DataFrame(score) for score in scores_dicts]\n",
    "#         scores = pd.concat(scores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c9d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca8cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
